{
 "metadata": {
  "name": "",
  "signature": "sha256:86ddbc25e9b4546d6af934b1517750dca18e4a72a8630e9d42a99e86ac85bb5c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Pagination\n",
      "\n",
      "Many APIs won't give you all the data you ask for at once. Just like Google results have \"next\" and \"previous\" buttons at the bottom, APIs will often have \"next\" and \"previous\" parameters in the response content or headers if there is more data to be had."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imports\n",
      "import requests\n",
      "from urlparse import urljoin"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if per_page is higher than the total number of repos, it gets them all\n",
      "response_all = requests.get('https://api.github.com/users/aschn/repos', params={'per_page': 20})\n",
      "print 'total number of repos:', len(response_all.json())\n",
      "\n",
      "# if per_page is lower, only get the first few\n",
      "response_pag = requests.get('https://api.github.com/users/aschn/repos', params={'per_page': 3})\n",
      "print 'number of repos returned:', len(response_pag.json())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total number of repos: 10\n",
        "number of repos returned:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# GitHub API puts the pagination info in an HTTP header named \"link\"\n",
      "print response_pag.headers['link']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<https://api.github.com/user/3664000/repos?per_page=3&page=2>; rel=\"next\", <https://api.github.com/user/3664000/repos?per_page=3&page=4>; rel=\"last\"\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here's an ugly little parser for the 'link' header\n",
      "links = response_pag.headers['link'].split(',')\n",
      "\n",
      "for linkrel in links:\n",
      "    ugly_link, rel = linkrel.strip().split(';')\n",
      "    if 'next' in rel:\n",
      "        link = ugly_link.lstrip('<').rstrip('>')\n",
      "        print 'next link is', link\n",
      "    elif 'last' in rel:\n",
      "        link = ugly_link.lstrip('<').rstrip('>')\n",
      "        print 'last link is', link"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "next link is https://api.github.com/user/3664000/repos?per_page=3&page=2\n",
        "last link is https://api.github.com/user/3664000/repos?per_page=3&page=4\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To use these links, we'll start by making a simple `GET` request. Then once we have the 'link' header, we can use a `while` loop to iterate over all the subsequent next links. The basic pattern is:\n",
      "\n",
      "```python\n",
      "next_url = first_url\n",
      "while next_url:\n",
      "    response = make_request(next_url)\n",
      "    next_url = get_next()\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a wrapper method for the GitHub API, with pagination\n",
      "def fetch_github_data(endpoint,\n",
      "                      method='get', base_url='https://api.github.com',\n",
      "                      **kwargs):\n",
      "    \"\"\"\n",
      "    By default makes a GET request to https://api.github.com/endpoint,\n",
      "    passing any kwargs to requests.\n",
      "    Returns the JSON-decoded response content, concatenating consecutive pages.\n",
      "    \"\"\"\n",
      "    # assemble url\n",
      "    next_url = urljoin(base_url, endpoint)\n",
      "    \n",
      "    # set up storage\n",
      "    data = []\n",
      "   \n",
      "    # loop over all available next urls\n",
      "    while next_url:\n",
      "        # log\n",
      "        print next_url\n",
      "        \n",
      "        # make next request\n",
      "        response = make_github_request(next_url, method, **kwargs)\n",
      "        \n",
      "        # concatenate JSON data\n",
      "        data += response.json()\n",
      "        \n",
      "        # extract next url\n",
      "        next_url = next_github_url(response)\n",
      "        \n",
      "    # return\n",
      "    return data\n",
      "    \n",
      "def make_github_request(url, method, **kwargs):    \n",
      "    # choose request method\n",
      "    try:\n",
      "        requester = getattr(requests, method.lower())\n",
      "    except AttributeError:\n",
      "        raise ValueError('%s is not a HTTP method' % method)\n",
      "    \n",
      "    # make request\n",
      "    response = requester(url, **kwargs)\n",
      "    \n",
      "    # return response\n",
      "    return response\n",
      "    \n",
      "def next_github_url(response):\n",
      "    \"\"\"Returns the next url\"\"\"\n",
      "    # split link header into next and last rels\n",
      "    try:\n",
      "        links = response.headers['link'].split(',')\n",
      "    except KeyError: # no link header\n",
      "        return None\n",
      "\n",
      "    # loop over link,rel pairs\n",
      "    for linkrel in links:\n",
      "        ugly_link, rel = linkrel.strip().split(';')\n",
      "        if 'next' in rel:\n",
      "            link = ugly_link.lstrip('<').rstrip('>')\n",
      "            return link\n",
      "    \n",
      "    # if got here, no next link\n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# testing\n",
      "data = fetch_github_data('users/aschn/repos', params={'per_page': 3})\n",
      "assert len(data) > 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "https://api.github.com/users/aschn/repos\n",
        "https://api.github.com/user/3664000/repos?per_page=3&page=2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "https://api.github.com/user/3664000/repos?per_page=3&page=3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "https://api.github.com/user/3664000/repos?per_page=3&page=4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}